# HarmonyGuard Utility Agent æ•°æ®éœ€æ±‚åˆ†æ

## Utility Agent éœ€è¦çš„å‚æ•°

`thought_aligner_response` æ–¹æ³•éœ€è¦ä»¥ä¸‹å‚æ•°ï¼š

```python
def thought_aligner_response(self, instruction, thought, trajectory, last_step_message):
```

### 1. `instruction` (ä»»åŠ¡æŒ‡ä»¤)
- **ç”¨é€”**: åœ¨ prompt ä¸­ä½œä¸º "TASK OBJECTIVE"
- **å½“å‰çŠ¶æ€**: âœ… **å·²æ­£ç¡®ä¼ é€’**
- **æ¥æº**: `evaluate_action_risk()` æ–¹æ³•çš„ `instruction` å‚æ•°

### 2. `thought` (Agent æ¨ç†è¿‡ç¨‹)
- **ç”¨é€”**: åœ¨ prompt ä¸­ä½œä¸º "AGENT REASONING"ï¼Œç”¨äºè¯„ä¼°æ¨ç†å’ŒåŠ¨ä½œ
- **å½“å‰çŠ¶æ€**: âœ… **å·²ä¼ é€’ï¼Œä½†å¯èƒ½éœ€è¦ä¼˜åŒ–**
- **æ¥æº**: `current_response`ï¼ˆå®Œæ•´çš„ LLM å“åº”ï¼ŒåŒ…æ‹¬æ¨ç†è¿‡ç¨‹ï¼‰
- **å½“å‰å®ç°**:
  ```python
  thought = current_response if current_response else str(action)
  ```
- **æ½œåœ¨é—®é¢˜**: 
  - `current_response` å¯èƒ½åŒ…å«ä»£ç å—ï¼Œéœ€è¦ç¡®è®¤æ˜¯å¦åº”è¯¥æå–çº¯æ¨ç†éƒ¨åˆ†
  - å¦‚æœ `current_response` ä¸ºç©ºï¼Œå›é€€åˆ° `str(action)`ï¼Œè¿™å¯èƒ½ä¸å¤Ÿå®Œæ•´

### 3. `trajectory` (è½¨è¿¹å†å²)
- **ç”¨é€”**: åœ¨æ–¹æ³•ç­¾åä¸­ï¼Œä½†åœ¨å½“å‰ prompt æ„å»ºä¸­**æ²¡æœ‰ç›´æ¥ä½¿ç”¨**
- **å½“å‰çŠ¶æ€**: âŒ **ä¼ é€’çš„æ˜¯ç©ºåˆ—è¡¨**
- **å½“å‰å®ç°**:
  ```python
  trajectory = []  # ç©ºåˆ—è¡¨
  ```
- **åˆ†æ**:
  - ä» `_get_prompt_with_evaluation` æ–¹æ³•æ¥çœ‹ï¼Œ`trajectory` å‚æ•°æ²¡æœ‰è¢«ä½¿ç”¨
  - ä½†åœ¨æŸäº›åœºæ™¯ä¸‹ï¼Œå†å²ä¸Šä¸‹æ–‡å¯èƒ½æœ‰åŠ©äºæ›´å‡†ç¡®çš„è¯„ä¼°
  - å¦‚æœéœ€è¦ï¼Œå¯ä»¥ä» `agent.actions`ã€`agent.thoughts`ã€`agent.observations` æ„å»º

### 4. `last_step_message` (ä¸Šä¸€æ­¥æ¶ˆæ¯)
- **ç”¨é€”**: åœ¨ prompt ä¸­ç”¨äº "taking into account the previous step"
- **å½“å‰çŠ¶æ€**: âš ï¸ **ä¼ é€’çš„æ˜¯å›ºå®šå­—ç¬¦ä¸²ï¼Œä¸å¤Ÿå‡†ç¡®**
- **å½“å‰å®ç°**:
  ```python
  last_step_message = "Previous step completed successfully"
  ```
- **é—®é¢˜**:
  - å›ºå®šå­—ç¬¦ä¸²æ— æ³•åæ˜ å®é™…çš„ä¸Šä¸€æ­¥æ‰§è¡Œç»“æœ
  - åº”è¯¥ä¼ é€’å®é™…çš„ä¸Šä¸€æ­¥åŠ¨ä½œå’Œæ‰§è¡Œç»“æœ
- **å»ºè®®**:
  - å¦‚æœæœ‰ä¸Šä¸€æ­¥çš„åŠ¨ä½œï¼Œåº”è¯¥ä¼ é€’ç±»ä¼¼ "Previous action: {action}, Result: {result}" çš„ä¿¡æ¯
  - å¦‚æœæ˜¯ç¬¬ä¸€æ­¥ï¼Œå¯ä»¥ä¼ é€’ "This is the first step" æˆ–ç±»ä¼¼ä¿¡æ¯

## Prompt æ„å»ºåˆ†æ

ä» `_get_prompt_with_evaluation` æ–¹æ³•æ¥çœ‹ï¼Œå®é™…ä½¿ç”¨çš„æ•°æ®ï¼š

1. **`policy_content`**: ä» `self._formatted_policy_content` è·å–ï¼ˆå·²åˆå§‹åŒ–ï¼‰
2. **`instruction`**: âœ… å·²ä¼ é€’
3. **`thought`**: âœ… å·²ä¼ é€’
4. **`last_step_message`**: âš ï¸ å·²ä¼ é€’ä½†ä¸å¤Ÿå‡†ç¡®
5. **`additional_guideline`**: å›ºå®šå­—ç¬¦ä¸²ï¼ˆåœ¨æ–¹æ³•å†…éƒ¨è®¾ç½®ï¼‰

**æ³¨æ„**: `trajectory` å‚æ•°åœ¨ prompt æ„å»ºä¸­**æ²¡æœ‰è¢«ä½¿ç”¨**ï¼Œä½†ä¿ç•™åœ¨æ–¹æ³•ç­¾åä¸­å¯èƒ½æ˜¯ä¸ºäº†æœªæ¥æ‰©å±•ã€‚

## å½“å‰æ•°æ®ä¼ é€’çŠ¶æ€

| å‚æ•° | éœ€è¦ | å·²ä¼ é€’ | å‡†ç¡®æ€§ | å¤‡æ³¨ |
|------|------|--------|--------|------|
| `instruction` | âœ… | âœ… | âœ… å‡†ç¡® | ä»»åŠ¡æŒ‡ä»¤æ­£ç¡®ä¼ é€’ |
| `thought` | âœ… | âœ… | âš ï¸ å¯èƒ½éœ€ä¼˜åŒ– | ä» `current_response` æå–ï¼Œå¯èƒ½åŒ…å«ä»£ç å— |
| `trajectory` | â“ | âŒ | âŒ ç©ºåˆ—è¡¨ | Prompt ä¸­æœªä½¿ç”¨ï¼Œä½†å¯èƒ½å¯¹æŸäº›åœºæ™¯æœ‰ç”¨ |
| `last_step_message` | âœ… | âš ï¸ | âŒ å›ºå®šå­—ç¬¦ä¸² | åº”è¯¥ä¼ é€’å®é™…çš„ä¸Šä¸€æ­¥ä¿¡æ¯ |

## æ”¹è¿›å»ºè®®

### 1. ä¼˜åŒ– `thought` æå–
å¦‚æœ `current_response` åŒ…å«ä»£ç å—ï¼Œå¯ä»¥è€ƒè™‘æå–çº¯æ¨ç†éƒ¨åˆ†ï¼š

```python
# æå–æ¨ç†éƒ¨åˆ†ï¼ˆæ’é™¤ä»£ç å—ï¼‰
def extract_thought(response: str) -> str:
    # ç§»é™¤ä»£ç å—ï¼Œä¿ç•™æ¨ç†æ–‡æœ¬
    import re
    # ç§»é™¤ ```python ... ``` ç­‰ä»£ç å—
    thought = re.sub(r'```[\w]*\n.*?```', '', response, flags=re.DOTALL)
    return thought.strip() or str(action)
```

### 2. æ”¹è¿› `last_step_message`
å¦‚æœæœ‰å†å²ä¿¡æ¯ï¼Œåº”è¯¥ä¼ é€’å®é™…çš„ä¸Šä¸€æ­¥ç»“æœï¼š

```python
# å¦‚æœæœ‰ä¸Šä¸€æ­¥åŠ¨ä½œ
if hasattr(self, 'last_action') and self.last_action:
    last_step_message = f"Previous action: {self.last_action}, Result: {self.last_result or 'completed'}"
elif hasattr(self, 'step_count') and self.step_count == 0:
    last_step_message = "This is the first step"
else:
    last_step_message = "Previous step completed successfully"
```

### 3. æ„å»º `trajectory`ï¼ˆå¯é€‰ï¼‰
å¦‚æœéœ€è¦å†å²ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥ä» agent çš„å†å²æ„å»ºï¼š

```python
# ä» agent å†å²æ„å»º trajectoryï¼ˆå¦‚æœå¯ç”¨ï¼‰
trajectory = []
if hasattr(self, 'agent') and hasattr(self.agent, 'actions'):
    # æ„å»ºç®€åŒ–çš„è½¨è¿¹å†å²
    for i, (action, thought, obs) in enumerate(zip(
        self.agent.actions[-3:],  # æœ€è¿‘3æ­¥
        self.agent.thoughts[-3:],
        self.agent.observations[-3:]
    )):
        trajectory.append({
            'step': i + 1,
            'action': str(action),
            'thought': str(thought)[:200],  # æˆªæ–­
            'observation': '...'  # ç®€åŒ–
        })
```

## ç»“è®º

âœ… **æ ¸å¿ƒæ•°æ®å·²ä¼ é€’**: `instruction` å’Œ `thought` å·²æ­£ç¡®ä¼ é€’ï¼Œè¿™æ˜¯è¯„ä¼°æ‰€éœ€çš„æ ¸å¿ƒæ•°æ®ã€‚

âš ï¸ **å¯ä¼˜åŒ–é¡¹**:
1. `last_step_message` åº”è¯¥ä¼ é€’å®é™…çš„ä¸Šä¸€æ­¥ä¿¡æ¯ï¼Œè€Œä¸æ˜¯å›ºå®šå­—ç¬¦ä¸²
2. `thought` æå–å¯èƒ½éœ€è¦ä¼˜åŒ–ï¼Œæ’é™¤ä»£ç å—
3. `trajectory` è™½ç„¶å½“å‰æœªä½¿ç”¨ï¼Œä½†å¯ä»¥è€ƒè™‘æ„å»ºä»¥æä¾›å†å²ä¸Šä¸‹æ–‡

ğŸ” **éœ€è¦ç¡®è®¤**:
- `current_response` çš„æ ¼å¼æ˜¯å¦åŒ…å«ä»£ç å—ï¼Œæ˜¯å¦éœ€è¦æå–çº¯æ¨ç†éƒ¨åˆ†
- æ˜¯å¦æœ‰å¯ç”¨çš„ä¸Šä¸€æ­¥åŠ¨ä½œå’Œæ‰§è¡Œç»“æœä¿¡æ¯
- æ˜¯å¦éœ€è¦æ„å»º `trajectory` å†å²ï¼ˆè™½ç„¶ prompt ä¸­æœªä½¿ç”¨ï¼‰
